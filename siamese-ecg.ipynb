{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\nfrom tensorflow.keras.models import Model\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Dataset\n# -----------------------------\ndata_dir = 'path_to_dataset'  # dataset folder containing subfolders for 3 classes\ndesired_width, desired_height = 224, 224\n\ndef load_dataset(data_dir, img_size=(224,224)):\n    classes = os.listdir(data_dir)\n    images, labels = [], []\n    for class_idx, class_name in enumerate(classes):\n        class_dir = os.path.join(data_dir, class_name)\n        for img_name in os.listdir(class_dir):\n            img_path = os.path.join(class_dir, img_name)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, img_size)\n            img = img.astype(np.float32) / 255.0\n            images.append(img)\n            labels.append(class_idx)\n    images = np.array(images)\n    labels = np.array(labels)\n    # shuffle\n    idx = np.arange(len(images))\n    np.random.shuffle(idx)\n    return images[idx], labels[idx], classes\n\nx_data, y_data, classes = load_dataset(data_dir)\n\n# Split into train/test\ntrain_split = int(0.8 * len(x_data))\nx_train, y_train = x_data[:train_split], y_data[:train_split]\nx_test, y_test = x_data[train_split:], y_data[train_split:]\n\n# -----------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build Siamese Network (Embedding Model)\n# -----------------------------\ninput_shape = (desired_height, desired_width, 3)\n\ndef create_base_cnn(input_shape):\n    inp = Input(shape=input_shape)\n    x = Conv2D(32, (3,3), activation='relu')(inp)\n    x = MaxPooling2D((2,2))(x)\n    x = Conv2D(64, (3,3), activation='relu')(x)\n    x = MaxPooling2D((2,2))(x)\n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)\n    model = Model(inp, x, name='base_cnn')\n    return model\n\nbase_cnn = create_base_cnn(input_shape)\n\n# Inputs for Siamese\ninput_left = Input(shape=input_shape)\ninput_right = Input(shape=input_shape)\n\n# Get embeddings\nembedding_left = base_cnn(input_left)\nembedding_right = base_cnn(input_right)\n\n# Contrastive Loss Distance\ndef euclidean_distance(vects):\n    x, y = vects\n    return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))\n\ndistance = tf.keras.layers.Lambda(euclidean_distance)([embedding_left, embedding_right])\n\n# Siamese Model\nsiamese_model = Model(inputs=[input_left, input_right], outputs=distance)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare Pairs for Training\n# -----------------------------\ndef create_pairs(x, y):\n    pairs, labels = [], []\n    num_classes = len(np.unique(y))\n    class_idx = [np.where(y==i)[0] for i in range(num_classes)]\n    for c in range(num_classes):\n        for i in range(len(class_idx[c])):\n            for j in range(i+1, len(class_idx[c])):\n                # positive pair\n                pairs += [[x[class_idx[c][i]], x[class_idx[c][j]]]]\n                labels += [1]\n                # negative pair\n                neg_c = (c + np.random.randint(1,num_classes)) % num_classes\n                neg_idx = np.random.choice(class_idx[neg_c])\n                pairs += [[x[class_idx[c][i]], x[neg_idx]]]\n                labels += [0]\n    return np.array(pairs), np.array(labels)\n\npairs_train, labels_train = create_pairs(x_train, y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile Siamese Model\n# -----------------------------\ndef contrastive_loss(y_true, y_pred, margin=1.0):\n    y_true = tf.cast(y_true, y_pred.dtype)\n    return tf.reduce_mean(y_true * tf.square(y_pred) + (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0)))\n\nsiamese_model.compile(optimizer='adam', loss=contrastive_loss, metrics=['accuracy'])\nsiamese_model.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train Siamese Model\n# -----------------------------\nepochs = 50\nbatch_size = 16\n\nsiamese_model.fit([pairs_train[:,0], pairs_train[:,1]], labels_train,\n                  batch_size=batch_size,\n                  epochs=epochs,\n                  verbose=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build Embeddings for Training Set\n# -----------------------------\ntrain_embeddings = base_cnn.predict(x_train)\ntest_embeddings = base_cnn.predict(x_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nearest Neighbor Classification\n# -----------------------------\ndef predict_class(test_emb, train_emb, train_labels):\n    preds = []\n    for emb in test_emb:\n        distances = np.linalg.norm(train_emb - emb, axis=1)\n        closest_idx = np.argmin(distances)\n        preds.append(train_labels[closest_idx])\n    return np.array(preds)\n\ny_pred = predict_class(test_embeddings, train_embeddings, y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate\n# -----------------------------\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-score: {f1:.4f}\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=classes, yticklabels=classes)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}